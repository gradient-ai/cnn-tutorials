{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  import dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as Datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from torchvision.utils import make_grid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The ConvNet classes\n",
    "\n",
    "We will use these for our benchmarking tasks later in the notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvNet_1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
    "    self.pool1 = nn.MaxPool2d(2)\n",
    "    self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "    self.pool2 = nn.MaxPool2d(2)\n",
    "    self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "    self.pool3 = nn.MaxPool2d(2)\n",
    "    self.conv4 = nn.Conv2d(32, 10, 1)\n",
    "    self.pool4 = nn.AvgPool2d(3)\n",
    "\n",
    "  def forward(self, x):\n",
    "    #-------------\n",
    "    # INPUT\n",
    "    #-------------\n",
    "    x = x.view(-1, 1, 28, 28)\n",
    "    \n",
    "    #-------------\n",
    "    # LAYER 1\n",
    "    #-------------\n",
    "    output_1 = self.conv1(x)\n",
    "    output_1 = F.relu(output_1)\n",
    "    output_1 = self.pool1(output_1)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 2\n",
    "    #-------------\n",
    "    output_2 = self.conv2(output_1)\n",
    "    output_2 = F.relu(output_2)\n",
    "    output_2 = self.pool2(output_2)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 3\n",
    "    #-------------\n",
    "    output_3 = self.conv3(output_2)\n",
    "    output_3 = F.relu(output_3)\n",
    "    output_3 = self.pool3(output_3)\n",
    "\n",
    "    #--------------\n",
    "    # OUTPUT LAYER\n",
    "    #--------------\n",
    "    output_4 = self.conv4(output_3)\n",
    "    output_4 = self.pool4(output_4)\n",
    "    output_4 = output_4.view(-1, 10)\n",
    "\n",
    "    return torch.sigmoid(output_4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvNet_2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "    self.pool1 = nn.MaxPool2d(2)\n",
    "    self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "    self.pool2 = nn.MaxPool2d(2)\n",
    "    self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "    self.pool3 = nn.MaxPool2d(2)\n",
    "    self.conv4 = nn.Conv2d(64, 10, 1)\n",
    "    self.pool4 = nn.AvgPool2d(3)\n",
    "\n",
    "  def forward(self, x):\n",
    "    #-------------\n",
    "    # INPUT\n",
    "    #-------------\n",
    "    x = x.view(-1, 1, 28, 28)\n",
    "    \n",
    "    #-------------\n",
    "    # LAYER 1\n",
    "    #-------------\n",
    "    output_1 = self.conv1(x)\n",
    "    output_1 = F.relu(output_1)\n",
    "    output_1 = self.pool1(output_1)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 2\n",
    "    #-------------\n",
    "    output_2 = self.conv2(output_1)\n",
    "    output_2 = F.relu(output_2)\n",
    "    output_2 = self.pool2(output_2)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 3\n",
    "    #-------------\n",
    "    output_3 = self.conv3(output_2)\n",
    "    output_3 = F.relu(output_3)\n",
    "    output_3 = self.pool3(output_3)\n",
    "\n",
    "    #--------------\n",
    "    # OUTPUT LAYER\n",
    "    #--------------\n",
    "    output_4 = self.conv4(output_3)\n",
    "    output_4 = self.pool4(output_4)\n",
    "    output_4 = output_4.view(-1, 10)\n",
    "\n",
    "    return torch.sigmoid(output_4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Changing depth"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvNet_3(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
    "    self.conv2 = nn.Conv2d(8, 8, 3, padding=1)\n",
    "    self.pool2 = nn.MaxPool2d(2)\n",
    "    self.conv3 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "    self.conv4 = nn.Conv2d(16, 16, 3, padding=1)\n",
    "    self.pool4 = nn.MaxPool2d(2)\n",
    "    self.conv5 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "    self.conv6 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "    self.pool6 = nn.MaxPool2d(2)\n",
    "    self.conv7 = nn.Conv2d(32, 10, 1)\n",
    "    self.pool7 = nn.AvgPool2d(3)\n",
    "\n",
    "  def forward(self, x):\n",
    "    #-------------\n",
    "    # INPUT\n",
    "    #-------------\n",
    "    x = x.view(-1, 1, 28, 28)\n",
    "    \n",
    "    #-------------\n",
    "    # LAYER 1\n",
    "    #-------------\n",
    "    output_1 = self.conv1(x)\n",
    "    output_1 = F.relu(output_1)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 2\n",
    "    #-------------\n",
    "    output_2 = self.conv2(output_1)\n",
    "    output_2 = F.relu(output_2)\n",
    "    output_2 = self.pool2(output_2)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 3\n",
    "    #-------------\n",
    "    output_3 = self.conv3(output_2)\n",
    "    output_3 = F.relu(output_3)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 4\n",
    "    #-------------\n",
    "    output_4 = self.conv4(output_3)\n",
    "    output_4 = F.relu(output_4)\n",
    "    output_4 = self.pool4(output_4)    \n",
    "\n",
    "    #-------------\n",
    "    # LAYER 5\n",
    "    #-------------\n",
    "    output_5 = self.conv5(output_4)\n",
    "    output_5 = F.relu(output_5)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 6\n",
    "    #-------------\n",
    "    output_6 = self.conv6(output_5)\n",
    "    output_6 = F.relu(output_6)\n",
    "    output_6 = self.pool6(output_6)\n",
    "\n",
    "    #--------------\n",
    "    # OUTPUT LAYER\n",
    "    #--------------\n",
    "    output_7 = self.conv7(output_6)\n",
    "    output_7 = self.pool7(output_7)\n",
    "    output_7 = output_7.view(-1, 10)\n",
    "\n",
    "    return torch.sigmoid(output_7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmarking Convnet Performance Based on Dimensions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvNet_4(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "    self.conv2 = nn.Conv2d(16, 16, 3, padding=1)\n",
    "    self.pool2 = nn.MaxPool2d(2)\n",
    "    self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "    self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "    self.pool4 = nn.MaxPool2d(2)\n",
    "    self.conv5 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "    self.conv6 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "    self.pool6 = nn.MaxPool2d(2)\n",
    "    self.conv7 = nn.Conv2d(64, 10, 1)\n",
    "    self.pool7 = nn.AvgPool2d(3)\n",
    "\n",
    "  def forward(self, x):\n",
    "    #-------------\n",
    "    # INPUT\n",
    "    #-------------\n",
    "    x = x.view(-1, 1, 28, 28)\n",
    "    \n",
    "    #-------------\n",
    "    # LAYER 1\n",
    "    #-------------\n",
    "    output_1 = self.conv1(x)\n",
    "    output_1 = F.relu(output_1)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 2\n",
    "    #-------------\n",
    "    output_2 = self.conv2(output_1)\n",
    "    output_2 = F.relu(output_2)\n",
    "    output_2 = self.pool2(output_2)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 3\n",
    "    #-------------\n",
    "    output_3 = self.conv3(output_2)\n",
    "    output_3 = F.relu(output_3)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 4\n",
    "    #-------------\n",
    "    output_4 = self.conv4(output_3)\n",
    "    output_4 = F.relu(output_4)\n",
    "    output_4 = self.pool4(output_4)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 5\n",
    "    #-------------\n",
    "    output_5 = self.conv5(output_4)\n",
    "    output_5 = F.relu(output_5)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 6\n",
    "    #-------------\n",
    "    output_6 = self.conv6(output_5)\n",
    "    output_6 = F.relu(output_6)\n",
    "    output_6 = self.pool6(output_6)\n",
    "\n",
    "    #--------------\n",
    "    # OUTPUT LAYER\n",
    "    #--------------\n",
    "    output_7 = self.conv7(output_6)\n",
    "    output_7 = self.pool7(output_7)\n",
    "    output_7 = output_7.view(-1, 10)\n",
    "\n",
    "    return torch.sigmoid(output_7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmark Dataset: FashionMNIST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  laoding training data\n",
    "training_set = Datasets.FashionMNIST(root='./', download=True,\n",
    "                                      transform=transforms.ToTensor())\n",
    "\n",
    "#  loading validation data\n",
    "validation_set = Datasets.FashionMNIST(root='./', download=True, train=False,\n",
    "                                        transform=transforms.ToTensor())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "val_loader = DataLoader(validation_set, 32)\n",
    "\n",
    "for images, labels in val_loader:\n",
    "  print(images.shape)\n",
    "  break\n",
    "  \n",
    "#  visualising images\n",
    "plt.figure(dpi=150)\n",
    "plt.title('images')\n",
    "plt.imshow(np.transpose(make_grid(images, padding=4, normalize=True), \n",
    "                        (1,2,0)))\n",
    "plt.axis('off')\n",
    "plt.savefig('fmnist.png', dpi=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutional Neural Network Class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  setup device\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "  print('Running on the GPU')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('Running on the CPU')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvolutionalNeuralNet():\n",
    "  def __init__(self, network):\n",
    "    self.network = network.to(device)\n",
    "    self.optimizer = torch.optim.Adam(self.network.parameters(), lr=3e-4)\n",
    "\n",
    "  def train(self, loss_function, epochs, batch_size, \n",
    "            training_set, validation_set):\n",
    "    \n",
    "    #  creating log\n",
    "    log_dict = {\n",
    "        'training_loss_per_batch': [],\n",
    "        'validation_loss_per_batch': [],\n",
    "        'training_accuracy_per_epoch': [],\n",
    "        'validation_accuracy_per_epoch': []\n",
    "    } \n",
    "\n",
    "    #  defining weight initialization function\n",
    "    def init_weights(module):\n",
    "      if isinstance(module, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(module.weight)\n",
    "        module.bias.data.fill_(0.01)\n",
    "\n",
    "    #  defining accuracy function\n",
    "    def accuracy(network, dataloader):\n",
    "      total_correct = 0\n",
    "      total_instances = 0\n",
    "      for images, labels in tqdm(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        predictions = torch.argmax(network(images), dim=1)\n",
    "        correct_predictions = sum(predictions==labels).item()\n",
    "        total_correct+=correct_predictions\n",
    "        total_instances+=len(images)\n",
    "      return round(total_correct/total_instances, 3)\n",
    "\n",
    "    #  initializing network weights\n",
    "    self.network.apply(init_weights)\n",
    "\n",
    "    #  creating dataloaders\n",
    "    train_loader = DataLoader(training_set, batch_size)\n",
    "    val_loader = DataLoader(validation_set, batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      print(f'Epoch {epoch+1}/{epochs}')\n",
    "      train_losses = []\n",
    "\n",
    "      #  training\n",
    "      print('training...')\n",
    "      for images, labels in tqdm(train_loader):\n",
    "        #  sending data to device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        #  resetting gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        #  making predictions\n",
    "        predictions = self.network(images)\n",
    "        #  computing loss\n",
    "        loss = loss_function(predictions, labels)\n",
    "        log_dict['training_loss_per_batch'].append(loss.item())\n",
    "        train_losses.append(loss.item())\n",
    "        #  computing gradients\n",
    "        loss.backward()\n",
    "        #  updating weights\n",
    "        self.optimizer.step()\n",
    "      with torch.no_grad():\n",
    "        print('deriving training accuracy...')\n",
    "        #  computing training accuracy\n",
    "        train_accuracy = accuracy(self.network, train_loader)\n",
    "        log_dict['training_accuracy_per_epoch'].append(train_accuracy)\n",
    "\n",
    "      #  validation\n",
    "      print('validating...')\n",
    "      val_losses = []\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "          #  sending data to device\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          #  making predictions\n",
    "          predictions = self.network(images)\n",
    "          #  computing loss\n",
    "          val_loss = loss_function(predictions, labels)\n",
    "          log_dict['validation_loss_per_batch'].append(val_loss.item())\n",
    "          val_losses.append(val_loss.item())\n",
    "        #  computing accuracy\n",
    "        print('deriving validation accuracy...')\n",
    "        val_accuracy = accuracy(self.network, val_loader)\n",
    "        log_dict['validation_accuracy_per_epoch'].append(val_accuracy)\n",
    "\n",
    "      train_losses = np.array(train_losses).mean()\n",
    "      val_losses = np.array(val_losses).mean()\n",
    "\n",
    "      print(f'training_loss: {round(train_losses, 4)}  training_accuracy: '+\n",
    "      f'{train_accuracy}  validation_loss: {round(val_losses, 4)} '+  \n",
    "      f'validation_accuracy: {val_accuracy}\\n')\n",
    "      \n",
    "    return log_dict\n",
    "\n",
    "  def predict(self, x):\n",
    "    return self.network(x)    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmarking results\n",
    "\n",
    "#### Convnet_1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  instantiating convnet_1\n",
    "model_1 = ConvolutionalNeuralNet(ConvNet_1())\n",
    "\n",
    "#  training convnet_1\n",
    "log_dict_1 = model_1.train(nn.CrossEntropyLoss(), epochs=10, batch_size=64, \n",
    "                           training_set=training_set, validation_set=validation_set)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  visualizing accuracies\n",
    "sns.lineplot(y=log_dict_1['training_accuracy_per_epoch'], x=range(len(log_dict_1['training_accuracy_per_epoch'])), label='training')\n",
    "\n",
    "sns.lineplot(y=log_dict_1['validation_accuracy_per_epoch'], x=range(len(log_dict_1['validation_accuracy_per_epoch'])), label='validation')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ConvNet_2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  instantiating convnet_2\n",
    "model_2 = ConvolutionalNeuralNet(ConvNet_2())\n",
    "\n",
    "#  training convnet_2\n",
    "log_dict_2 = model_2.train(nn.CrossEntropyLoss(), epochs=10, batch_size=64, \n",
    "                           training_set=training_set, validation_set=validation_set)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  visualizing accuracies\n",
    "sns.lineplot(y=log_dict_2['training_accuracy_per_epoch'], x=range(len(log_dict_2['training_accuracy_per_epoch'])), label='training')\n",
    "\n",
    "sns.lineplot(y=log_dict_2['validation_accuracy_per_epoch'], x=range(len(log_dict_2['validation_accuracy_per_epoch'])), label='validation')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ConvNet_3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  instantiating convnet_3\n",
    "model_3 = ConvolutionalNeuralNet(ConvNet_3())\n",
    "\n",
    "#  training convnet_3\n",
    "log_dict_3 = model_3.train(nn.CrossEntropyLoss(), epochs=10, batch_size=64, \n",
    "                           training_set=training_set, validation_set=validation_set)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  visualizing accuracies\n",
    "sns.lineplot(y=log_dict_3['training_accuracy_per_epoch'], x=range(len(log_dict_3['training_accuracy_per_epoch'])), label='training')\n",
    "\n",
    "sns.lineplot(y=log_dict_3['validation_accuracy_per_epoch'], x=range(len(log_dict_3['validation_accuracy_per_epoch'])), label='validation')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ConvNet_4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  instantiating convnet_4\n",
    "model_4 = ConvolutionalNeuralNet(ConvNet_4())\n",
    "\n",
    "#  training convnet_4\n",
    "log_dict_4 = model_4.train(nn.CrossEntropyLoss(), epochs=10, batch_size=64, \n",
    "                           training_set=training_set, validation_set=validation_set)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  visualizing accuracies\n",
    "sns.lineplot(y=log_dict_4['training_accuracy_per_epoch'], x=range(len(log_dict_4['training_accuracy_per_epoch'])), label='training')\n",
    "\n",
    "sns.lineplot(y=log_dict_4['validation_accuracy_per_epoch'], x=range(len(log_dict_4['validation_accuracy_per_epoch'])), label='validation')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}